[INFO|utils|numexpr.utils|L160] - 2024-06-03 00:35:37  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 00:35:53  ->  Using proactor: IocpProactor
[INFO|beautifulCrawler|WEB_SCRAPER|L393] - 2024-06-03 00:35:53  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L401] - 2024-06-03 00:35:54  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 00:35:54  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 00:35:54  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 00:35:54  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 00:35:56  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 00:35:57  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 00:35:57  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 00:36:00  ->  Getting page: https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 00:36:00  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 00:36:00  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 00:36:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 00:36:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 00:36:01  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L74] - 2024-06-03 00:36:01  ->  Connecting to database mysql
[ERROR|storage|WEB_SCRAPER|L86] - 2024-06-03 00:36:01  ->  Unable to Connect to database!!!
[ERROR|storage|WEB_SCRAPER|L87] - 2024-06-03 00:36:01  ->  Exception: TypeError: __init__() got an unexpected keyword argument 'pool_name'
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 00:36:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 00:36:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 00:36:01  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L74] - 2024-06-03 00:36:01  ->  Connecting to database mysql
[ERROR|storage|WEB_SCRAPER|L86] - 2024-06-03 00:36:01  ->  Unable to Connect to database!!!
[ERROR|storage|WEB_SCRAPER|L87] - 2024-06-03 00:36:01  ->  Exception: TypeError: __init__() got an unexpected keyword argument 'pool_name'
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 00:36:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 00:36:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 00:36:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 00:36:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 00:36:01  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L74] - 2024-06-03 00:36:01  ->  Connecting to database mysql
[ERROR|storage|WEB_SCRAPER|L86] - 2024-06-03 00:36:01  ->  Unable to Connect to database!!!
[ERROR|storage|WEB_SCRAPER|L87] - 2024-06-03 00:36:01  ->  Exception: TypeError: __init__() got an unexpected keyword argument 'pool_name'
[INFO|beautifulCrawler|WEB_SCRAPER|L424] - 2024-06-03 00:36:01  ->  Process completed in time:  7.82s
[ERROR|base_events|asyncio|L1753] - 2024-06-03 00:36:02  ->  Task exception was never retrieved
future: <Task finished name='Task-4' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:429> exception=TypeError("__init__() got an unexpected keyword argument 'pool_name'")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 454, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 343, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 289, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 276, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 379, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 131, in insert_data
    await self.connect_to_db()
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 110, in connect_to_db
    await self.create_tables()
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 123, in create_tables
    async with await connect(pool_name='mypool') as cnx:
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\mysql\connector\aio\__init__.py", line 162, in connect
    cnx = MySQLConnection(*args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'pool_name'
[ERROR|base_events|asyncio|L1753] - 2024-06-03 00:36:02  ->  Task exception was never retrieved
future: <Task finished name='Task-3' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:429> exception=TypeError("__init__() got an unexpected keyword argument 'pool_name'")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 454, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 343, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 289, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 276, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 379, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 131, in insert_data
    await self.connect_to_db()
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 110, in connect_to_db
    await self.create_tables()
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 123, in create_tables
    async with await connect(pool_name='mypool') as cnx:
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\mysql\connector\aio\__init__.py", line 162, in connect
    cnx = MySQLConnection(*args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'pool_name'
[ERROR|base_events|asyncio|L1753] - 2024-06-03 00:36:02  ->  Task exception was never retrieved
future: <Task finished name='Task-2' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:429> exception=TypeError("__init__() got an unexpected keyword argument 'pool_name'")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 454, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 343, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 289, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 276, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 379, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 131, in insert_data
    await self.connect_to_db()
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 110, in connect_to_db
    await self.create_tables()
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 123, in create_tables
    async with await connect(pool_name='mypool') as cnx:
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\mysql\connector\aio\__init__.py", line 162, in connect
    cnx = MySQLConnection(*args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'pool_name'
[INFO|utils|numexpr.utils|L160] - 2024-06-03 01:39:18  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 01:39:30  ->  Using proactor: IocpProactor
[INFO|beautifulCrawler|WEB_SCRAPER|L393] - 2024-06-03 01:39:31  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L401] - 2024-06-03 01:39:31  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 01:39:31  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 01:39:31  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 01:39:31  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:33  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:34  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:34  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:38  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:38  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:38  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:38  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:38  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:38  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:38  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:39  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 01:39:39  ->  Connecting to database mysql
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:39  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 01:39:39  ->  Connecting to database mysql
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:39  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 01:39:39  ->  Connecting to database mysql
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:39:39  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:39:39  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:39:39  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 01:39:39  ->  Successfully Connected to database!
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 01:39:39  ->  Successfully Connected to database!
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 01:39:39  ->  Successfully Connected to database!
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:42  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:42  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:42  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:42  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:42  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:42  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:42  ->  Moving on!
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:42  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:42  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:42  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:42  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:42  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:42  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:42  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:42  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:42  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:42  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:42  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:42  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:44  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:44  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:44  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:45  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:45  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:45  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:45  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:45  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:45  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:45  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:45  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:45  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:45  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:45  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:45  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:45  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:45  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:45  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:45  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:45  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:45  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:45  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:45  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:45  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:45  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:45  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:45  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:45  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:45  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:45  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:45  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/classics_6/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:47  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:47  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:47  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:47  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:47  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:47  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:47  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:47  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:47  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:47  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:47  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:47  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:47  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:47  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:47  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:47  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:47  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:47  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:47  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:47  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:48  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:48  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:48  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:48  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:48  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:48  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:48  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:48  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:48  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:48  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:48  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:48  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:48  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:48  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:48  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:48  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:48  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:48  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:48  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:48  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:48  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:48  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:49  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/romance_8/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:50  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:50  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:50  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:50  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:50  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:50  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:50  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:50  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:50  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:50  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:50  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:50  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:50  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:50  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:50  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:50  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:50  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:50  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:50  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:50  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:50  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:50  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:50  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:50  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:50  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:50  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:50  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:50  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:50  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:50  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:50  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:50  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:50  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:52  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:52  ->  Getting page: https://books.toscrape.com/catalogue/category/books/romance_8/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:52  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:53  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:53  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:53  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:53  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:53  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:53  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:53  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:53  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:53  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:53  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:53  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:53  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:53  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:53  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:53  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:53  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:53  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:53  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:53  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:53  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:53  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:53  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:53  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:53  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:53  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:53  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:53  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:53  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:53  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:53  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:53  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/childrens_11/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/religion_12/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:55  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:55  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:55  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:55  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:55  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:55  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:55  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:55  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:55  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:55  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:55  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:55  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:55  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:55  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:55  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:55  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:55  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:55  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:55  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:55  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:55  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:55  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:55  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:56  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:56  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:56  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:56  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:56  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:56  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:56  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:56  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:56  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:56  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:56  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:56  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:56  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:56  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:56  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:56  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:56  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:56  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:56  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:56  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:57  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:57  ->  Getting page: https://books.toscrape.com/catalogue/category/books/childrens_11/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:39:58  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:58  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:58  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:58  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:58  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:58  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:58  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:58  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:58  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:58  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:58  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:58  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:58  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:58  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:58  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:58  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:58  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:58  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:58  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:58  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:39:58  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:39:58  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:39:58  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:39:58  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:39:58  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:39:58  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:39:58  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:39:58  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:39:58  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:39:58  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:39:58  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:39:58  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:39:58  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:39:59  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:00  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:00  ->  Getting page: https://books.toscrape.com/catalogue/category/books/music_14/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:01  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:01  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:01  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:01  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:01  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:01  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:01  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:01  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:01  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:01  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:01  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:01  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:01  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:01  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:01  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:01  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:01  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:01  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:01  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:01  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:01  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:01  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:01  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:01  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:01  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:01  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:01  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:03  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:03  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:03  ->  Getting page: https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:03  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:03  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:03  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:03  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:03  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:03  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:03  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:03  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:03  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:03  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:03  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:03  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:03  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:03  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:03  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:03  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:03  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:03  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:03  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:03  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:03  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:04  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:04  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:04  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:04  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:04  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:04  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:04  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:04  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:04  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:04  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:04  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:04  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:04  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:04  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:04  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:04  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:04  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:04  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:04  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:04  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:04  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:04  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:05  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:06  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:06  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:06  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:06  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:06  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:06  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:06  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:06  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:06  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:06  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:06  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:06  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:06  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:06  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:06  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:06  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:06  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:06  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:06  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:06  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:06  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:06  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:06  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:06  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:06  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:06  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:06  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:06  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:06  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:06  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:06  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:06  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-5.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:09  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:09  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:09  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:09  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:09  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:09  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:09  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:09  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:09  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:09  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:09  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:09  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:09  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:09  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:09  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:09  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:09  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:09  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:10  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:10  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:10  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:10  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:10  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:10  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:10  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:10  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:10  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:10  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:10  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:10  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:10  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:10  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:10  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:10  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:10  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:10  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:10  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:10  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:10  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:10  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:10  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:10  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:11  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-6.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:11  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:11  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:11  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:11  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:11  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:11  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:11  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:11  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:11  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:11  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:12  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:12  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:12  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:12  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:12  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:12  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:12  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:12  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:12  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:12  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:12  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:12  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:12  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:12  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:12  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:12  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:12  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:12  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:12  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:12  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:12  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:12  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:12  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:12  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:12  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:12  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:12  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:12  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:12  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:12  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:12  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:12  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:12  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:13  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:13  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:13  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:13  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:13  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:13  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:13  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:13  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:13  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:13  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:13  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:13  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:13  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:13  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:13  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:13  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:13  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:13  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:13  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:13  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:14  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:14  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:14  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:14  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:14  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:14  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:14  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:14  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:14  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:14  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:14  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:14  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:14  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:14  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:14  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:14  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:14  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:14  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:14  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:14  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:14  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:14  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:15  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-5.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:16  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:17  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:17  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:17  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:17  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:17  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:17  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:17  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:17  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:17  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:17  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:17  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:17  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:17  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:17  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:17  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:17  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:17  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:17  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:17  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:17  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:17  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:18  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:18  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:18  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:18  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:18  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:18  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:18  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:18  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:18  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:18  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:18  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:18  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:18  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:18  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:18  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:18  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:18  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:18  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:18  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:18  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:18  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:19  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-6.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:20  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:20  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:20  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:20  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:20  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:20  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:20  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:20  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:20  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:20  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:20  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:20  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:20  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:20  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:20  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:20  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:20  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:20  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:20  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:20  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:20  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:20  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:20  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:20  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:20  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:20  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:20  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:20  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:20  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:20  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:21  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:21  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:21  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:21  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:21  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:21  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:22  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-7.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:23  ->  Getting page: https://books.toscrape.com/catalogue/category/books/new-adult_20/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:23  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:23  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:23  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:23  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:23  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:23  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:23  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:23  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:23  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:23  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:23  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:23  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:23  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:23  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:23  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:23  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:23  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:23  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:23  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:23  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:23  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:23  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:23  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:23  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:23  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:23  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:23  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:23  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:23  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:23  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:23  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:25  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-8.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:25  ->  Getting page: https://books.toscrape.com/catalogue/category/books/science_22/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:25  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:25  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:25  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:25  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:25  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:25  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:25  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:25  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:25  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:25  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:25  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:25  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:25  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:25  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:25  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:25  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:25  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:25  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:25  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:25  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:25  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:25  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:26  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:26  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:26  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:26  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:26  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:26  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:26  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:26  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:26  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:26  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:26  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:26  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:26  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:26  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:26  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:26  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:26  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:26  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:26  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:26  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:26  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:26  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:26  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:27  ->  Getting page: https://books.toscrape.com/catalogue/category/books/poetry_23/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:28  ->  Getting page: https://books.toscrape.com/catalogue/category/books/paranormal_24/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:28  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:28  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:28  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:28  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:28  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:28  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:28  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:28  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:28  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:28  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:28  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:28  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:28  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:28  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:28  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:28  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:28  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:29  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:29  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:29  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:29  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:29  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:29  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:29  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:29  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:29  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:29  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:29  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:29  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:29  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:29  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:29  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:29  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:29  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:29  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:29  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:29  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:29  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:29  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:29  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:29  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:29  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:29  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:29  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:29  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:29  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:30  ->  Getting page: https://books.toscrape.com/catalogue/category/books/art_25/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:31  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:31  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:31  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:31  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:31  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:31  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:31  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:31  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:31  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:31  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:31  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:31  ->  Getting page: https://books.toscrape.com/catalogue/category/books/psychology_26/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:31  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:31  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:31  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:31  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:31  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:31  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:31  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:31  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:31  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:31  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:31  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:31  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:31  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:31  ->  Getting page: https://books.toscrape.com/catalogue/category/books/autobiography_27/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:32  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:32  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:32  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:32  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:32  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:32  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:32  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:32  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:32  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:32  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:32  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:32  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:32  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:32  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:32  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:32  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:32  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:32  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:32  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:32  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:32  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:33  ->  Getting page: https://books.toscrape.com/catalogue/category/books/parenting_28/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:33  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:33  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:33  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:33  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:33  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:33  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:33  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:33  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:33  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:33  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:33  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:33  ->  Getting page: https://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:33  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:33  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:33  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:33  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:33  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:33  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:33  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:34  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:34  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:34  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:34  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:34  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:34  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/humor_30/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:34  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:34  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:34  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:34  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:34  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:34  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:34  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:34  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:34  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:34  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:34  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:34  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:34  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:34  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:34  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:34  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:34  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:34  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:34  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:34  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:34  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:35  ->  Getting page: https://books.toscrape.com/catalogue/category/books/horror_31/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:36  ->  Getting page: https://books.toscrape.com/catalogue/category/books/history_32/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:36  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:36  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:36  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:36  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:36  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:36  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:36  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:36  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:36  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:36  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:36  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:36  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:36  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:36  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:36  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:36  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:36  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:36  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:36  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:36  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:36  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:36  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:36  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:36  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:36  ->  Getting page: https://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:37  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:37  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:37  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:37  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:37  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:37  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:37  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:37  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:37  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:37  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:37  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:37  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:37  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:37  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:37  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:37  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:37  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:37  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:37  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:40:37  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:38  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:38  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:38  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:38  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:38  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:38  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:38  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:38  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:38  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:38  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:38  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:38  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:38  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:38  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:38  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:38  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:38  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:38  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:38  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:38  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:38  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/business_35/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:39  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:39  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:39  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:39  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:39  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:39  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:39  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:39  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:39  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:40  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:40  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:40  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:40  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:40  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:40  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:40  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:40  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:40  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:40  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:40  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:40  ->  Getting page: https://books.toscrape.com/catalogue/category/books/biography_36/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:40  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:40  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:40  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:40  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:40  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:40  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:41  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:41  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:41  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:41  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:41  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:41  ->  Getting page: https://books.toscrape.com/catalogue/category/books/thriller_37/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:41  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:41  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:41  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:41  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:41  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:41  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:41  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:42  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:42  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:42  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:42  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:42  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:42  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:42  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:42  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:42  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:42  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:42  ->  Getting page: https://books.toscrape.com/catalogue/category/books/contemporary_38/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:42  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:42  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:42  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:42  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:42  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:42  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:42  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:42  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:42  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:42  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:42  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:42  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:42  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:42  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:42  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:42  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:43  ->  Getting page: https://books.toscrape.com/catalogue/category/books/spirituality_39/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:43  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:43  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:43  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:43  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:43  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:43  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:43  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:43  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:43  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:43  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:43  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:43  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:43  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:43  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:43  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:43  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:43  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:43  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:43  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:43  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:43  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:44  ->  Getting page: https://books.toscrape.com/catalogue/category/books/academic_40/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:44  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:44  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:44  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:44  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:44  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:44  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:44  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:44  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:44  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:44  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:44  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:44  ->  Getting page: https://books.toscrape.com/catalogue/category/books/self-help_41/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:44  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:44  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:44  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:44  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:44  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:44  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:44  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:44  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:44  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:44  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:44  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:44  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:44  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:45  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical_42/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:45  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:45  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:45  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:45  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:45  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:45  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:45  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:45  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:45  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:45  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:45  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:45  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:45  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:45  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:45  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:45  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:45  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:45  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:45  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:46  ->  Getting page: https://books.toscrape.com/catalogue/category/books/christian_43/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:46  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:46  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:46  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:46  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:46  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:46  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:46  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:46  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:46  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:46  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:46  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:46  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:46  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:46  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:46  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:46  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:46  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:46  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:46  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:46  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:46  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:46  ->  Getting page: https://books.toscrape.com/catalogue/category/books/suspense_44/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:47  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:47  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:47  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:47  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:47  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:47  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:47  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:47  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:47  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:47  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:47  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:47  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:47  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:47  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:47  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:47  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:47  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:47  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:47  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:47  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:47  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/short-stories_45/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:48  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:48  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:48  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:48  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:48  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:48  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:48  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:48  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:48  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:48  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:48  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:48  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:48  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:48  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:48  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:48  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:48  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:48  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:48  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:48  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:48  ->  Getting page: https://books.toscrape.com/catalogue/category/books/novels_46/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:49  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:49  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:49  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:49  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:49  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:49  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:49  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:49  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:49  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:49  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:49  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:49  ->  Getting page: https://books.toscrape.com/catalogue/category/books/health_47/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:49  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:49  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:49  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:49  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:49  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:49  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:49  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:49  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:49  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:49  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:49  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:49  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:49  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/politics_48/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:50  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:50  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:50  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:50  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:50  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:50  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:50  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:50  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:50  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:50  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:50  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:50  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:50  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:50  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:50  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:50  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:50  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:50  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:50  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:50  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:50  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:51  ->  Getting page: https://books.toscrape.com/catalogue/category/books/cultural_49/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:51  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:51  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:51  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:51  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:51  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:51  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:51  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:51  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:51  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:51  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:51  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:51  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:51  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:51  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:51  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:51  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:51  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:51  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:51  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:51  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:51  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L456] - 2024-06-03 01:40:51  ->  Worker-2 completed task in time:  80.32s
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:51  ->  Getting page: https://books.toscrape.com/catalogue/category/books/erotica_50/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:52  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:52  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:52  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:52  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:52  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:52  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:52  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:52  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:52  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:52  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:52  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L456] - 2024-06-03 01:40:52  ->  Worker-1 completed task in time:  81.06s
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:40:52  ->  Getting page: https://books.toscrape.com/catalogue/category/books/crime_51/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:40:52  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:40:52  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:40:52  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:40:52  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:40:52  ->  saving data to db storage: BookScrape
[ERROR|storage|WEB_SCRAPER|L170] - 2024-06-03 01:40:52  ->  Unable to get row_id!!!
[ERROR|storage|WEB_SCRAPER|L171] - 2024-06-03 01:40:52  ->  Exception: AttributeError: 'Cursor' object has no attribute 'reset'
[INFO|storage|WEB_SCRAPER|L174] - 2024-06-03 01:40:52  ->  Saving to file instead
[INFO|pipeline_funcs|WEB_SCRAPER|L158] - 2024-06-03 01:40:52  ->  Output/BookScrape failed_data.csv.csv saved Successfully!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:40:52  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:40:52  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:40:52  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:40:52  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L456] - 2024-06-03 01:40:52  ->  Worker-3 completed task in time:  81.57s
[INFO|beautifulCrawler|WEB_SCRAPER|L424] - 2024-06-03 01:40:52  ->  Process completed in time:  81.58s
[INFO|utils|numexpr.utils|L160] - 2024-06-03 01:42:26  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 01:42:28  ->  Using proactor: IocpProactor
[INFO|beautifulCrawler|WEB_SCRAPER|L393] - 2024-06-03 01:42:28  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L401] - 2024-06-03 01:42:28  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 01:42:28  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 01:42:28  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L452] - 2024-06-03 01:42:28  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:30  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:31  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:31  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:34  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:34  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:34  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:34  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:34  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:34  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:34  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:34  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:34  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:34  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:34  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:34  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:34  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 01:42:34  ->  Connecting to database mysql
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:34  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:35  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:35  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 01:42:35  ->  Connecting to database mysql
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:35  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:35  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:35  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:35  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:35  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 01:42:35  ->  Connecting to database mysql
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:42:35  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:42:35  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:42:35  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 01:42:35  ->  Successfully Connected to database!
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 01:42:35  ->  Successfully Connected to database!
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 01:42:35  ->  Successfully Connected to database!
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:42:35  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 01:42:35  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:39  ->  11 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:39  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:39  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:42:39  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:42:39  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:40  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:40  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:40  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:42:40  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:40  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:40  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:40  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:42:40  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:41  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:41  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:41  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:41  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:41  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:41  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:41  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:41  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:41  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:41  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:41  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:41  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:41  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:41  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:42  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:42  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:43  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:43  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:43  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:43  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:43  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:43  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:43  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:43  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:45  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:45  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:42:45  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:42:45  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:45  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:45  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:42:45  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:46  ->  12 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:46  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:46  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:42:46  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:42:46  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/classics_6/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:47  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:47  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:47  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:47  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:47  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:47  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:47  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:47  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:47  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:47  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:47  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:47  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:47  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:48  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:48  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:48  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:48  ->  Getting page: https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:48  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:48  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:48  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:48  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:48  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:50  ->  11 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:50  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:50  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:42:50  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:42:50  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:51  ->  19 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:51  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:51  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:42:51  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:42:51  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:51  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:51  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:51  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:42:51  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:52  ->  Getting page: https://books.toscrape.com/catalogue/category/books/romance_8/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:53  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:53  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:53  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:53  ->  Getting page: https://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:53  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:53  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:53  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:53  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:42:53  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:42:53  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:42:53  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:42:53  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:42:53  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:57  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:57  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:57  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:42:57  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:58  ->  17 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:58  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:58  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:42:58  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:42:58  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:42:58  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:42:58  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:42:58  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:42:58  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:42:59  ->  Getting page: https://books.toscrape.com/catalogue/category/books/romance_8/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:00  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:00  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:00  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:00  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:00  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:00  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:00  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:00  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:00  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:00  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:01  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:06  ->  15 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:06  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:06  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:06  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:07  ->  15 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:07  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:07  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:07  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:07  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:08  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:08  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:08  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:08  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/childrens_11/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:09  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:09  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:09  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:09  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:09  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:09  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:09  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:09  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:09  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:09  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:09  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:09  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:09  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:09  ->  Getting page: https://books.toscrape.com/catalogue/category/books/religion_12/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:10  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:10  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:10  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:10  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:10  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:10  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:10  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:10  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:10  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:11  ->  7 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:11  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:11  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:11  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:11  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:12  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:12  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:12  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:12  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:13  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:13  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:13  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:13  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:13  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:14  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:14  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:14  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:14  ->  Getting page: https://books.toscrape.com/catalogue/category/books/childrens_11/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:14  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:14  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:14  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:14  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:14  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:15  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:16  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:16  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:16  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:16  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:16  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:16  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:16  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:16  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:16  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:16  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:16  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:16  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:16  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:16  ->  9 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:16  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:16  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:16  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:16  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:17  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:17  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:17  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:17  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:18  ->  Getting page: https://books.toscrape.com/catalogue/category/books/music_14/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:19  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:19  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:19  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:19  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:19  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:19  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:19  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:19  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:19  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:19  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:19  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:19  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:19  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:19  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:19  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:19  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:19  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:19  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:20  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:20  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:20  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:20  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:20  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:20  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:20  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:20  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:20  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:20  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:20  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:20  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:20  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:20  ->  13 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:20  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:20  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:20  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:20  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:21  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:21  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:21  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:21  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:21  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:21  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:21  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:21  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:21  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:21  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:21  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:21  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:21  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:21  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:22  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:22  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:22  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:22  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:22  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:22  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:23  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:23  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:23  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:23  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:23  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:23  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:23  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:23  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:23  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:23  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:23  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:23  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:23  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:23  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:23  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:23  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:24  ->  Getting page: https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:25  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:25  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:25  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:25  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:25  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:25  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:25  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:25  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:25  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:25  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:25  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:25  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:25  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:25  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-3.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:26  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:26  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:26  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:26  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:26  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:26  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:26  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:26  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:26  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:26  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:26  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:26  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:26  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:26  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:26  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:26  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:26  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:27  ->  16 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:27  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:27  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:27  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:27  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:28  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:28  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:28  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:28  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:28  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:28  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:28  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:28  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:28  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:28  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:28  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:28  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:28  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:28  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:29  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:29  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:29  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:29  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:29  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:29  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:29  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:29  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:29  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:29  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:29  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:29  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:29  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:29  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:29  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:29  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:29  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:29  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:30  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:30  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:30  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:30  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:30  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:31  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:31  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:31  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:31  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:31  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:31  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:31  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:31  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:31  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:31  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:31  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:31  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:31  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:31  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:31  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:31  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:31  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:31  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:32  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:33  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:33  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:33  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:33  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:33  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:33  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:33  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:33  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:33  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:34  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:34  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:34  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:34  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:36  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:36  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:36  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:36  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:36  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-5.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:36  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:36  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:36  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:36  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:37  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:37  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:37  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:37  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:37  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:37  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:37  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:37  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:37  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:37  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:37  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:37  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:37  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:39  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:39  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:39  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:39  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:39  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:39  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:41  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-6.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:41  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:41  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:41  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:41  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:42  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:42  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:42  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:42  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:42  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:42  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:42  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:42  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:42  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:42  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:42  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:42  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:42  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:42  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:42  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:42  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:43  ->  10 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:43  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:43  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:43  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:43  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:43  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:44  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:44  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:44  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:44  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:44  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:44  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:44  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:44  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:44  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:44  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:44  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:44  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:44  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:44  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-5.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:45  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:45  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:45  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:45  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:45  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:45  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:45  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:45  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:45  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:45  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:45  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:45  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:45  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:46  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:46  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:46  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:46  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:46  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:46  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:46  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:46  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:46  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:46  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:46  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:46  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:46  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:46  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:46  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:46  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:46  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:48  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:48  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:48  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:48  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:48  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:48  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:48  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-4.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:49  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:49  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:49  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:49  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:49  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:49  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:49  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:49  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:49  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:49  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:49  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:49  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:49  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:49  ->  7 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:49  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:49  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:49  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:49  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-6.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:50  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:50  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:50  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:50  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:50  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:50  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:50  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:50  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:50  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:50  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:50  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:50  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:50  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:51  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:51  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:51  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:51  ->  Getting page: https://books.toscrape.com/catalogue/category/books/new-adult_20/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:51  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:51  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:51  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:51  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:51  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:52  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:52  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:52  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:52  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:52  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:53  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:53  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:53  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:53  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:53  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:53  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:54  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-7.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:55  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:55  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:55  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:55  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:55  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:55  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:55  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:55  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:56  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:56  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:56  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:56  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:56  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:56  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:56  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:56  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:56  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:56  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:56  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:56  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:56  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:57  ->  8 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:57  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:57  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:43:57  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:43:57  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:43:59  ->  Getting page: https://books.toscrape.com/catalogue/category/books/science_22/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:43:59  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:43:59  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:43:59  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:43:59  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:43:59  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:43:59  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:59  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:59  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:59  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:59  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:59  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:59  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:59  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:59  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:43:59  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:43:59  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:43:59  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:01  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:02  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:02  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:02  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:02  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:02  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:02  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:02  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:02  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:02  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:02  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:02  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:02  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:02  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:02  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:02  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:02  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:44:02  ->  going to next page
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:04  ->  14 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:04  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:04  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:04  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:04  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:04  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-8.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:04  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:04  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:04  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:04  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:04  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:04  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:04  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:04  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:04  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:04  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:04  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:04  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:04  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:06  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:06  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:44:06  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:06  ->  Getting page: https://books.toscrape.com/catalogue/category/books/poetry_23/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:06  ->  12 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:06  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:06  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:06  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:06  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:06  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:06  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:06  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:06  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:06  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:06  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:06  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:06  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:06  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:06  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:06  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:06  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/page-3.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/paranormal_24/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:08  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:08  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:08  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:08  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:08  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:08  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:08  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:08  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:08  ->  19 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:08  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:08  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:08  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:08  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:08  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:08  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:08  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:08  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:08  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:10  ->  14 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:10  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:10  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:10  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:10  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:10  ->  Getting page: https://books.toscrape.com/catalogue/category/books/art_25/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:10  ->  Getting page: https://books.toscrape.com/catalogue/category/books/psychology_26/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:11  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:11  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:11  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:11  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:11  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:11  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:11  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:11  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:12  ->  Getting page: https://books.toscrape.com/catalogue/category/books/autobiography_27/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:12  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:12  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:12  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:12  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:12  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:12  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:12  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:12  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:12  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:12  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:12  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:12  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:12  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:13  ->  7 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:13  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:13  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:13  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:13  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:13  ->  8 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:13  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:13  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:13  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:13  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:15  ->  Getting page: https://books.toscrape.com/catalogue/category/books/parenting_28/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:15  ->  Getting page: https://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:15  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:15  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:15  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:15  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:15  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:15  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:15  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:15  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:16  ->  9 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:16  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:16  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:16  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:16  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:16  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:16  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:16  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:16  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:16  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:16  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:16  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:16  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:16  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:16  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:18  ->  Getting page: https://books.toscrape.com/catalogue/category/books/humor_30/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:18  ->  Getting page: https://books.toscrape.com/catalogue/category/books/horror_31/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:18  ->  Getting page: https://books.toscrape.com/catalogue/category/books/history_32/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:18  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:18  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:18  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:18  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:18  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:18  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:18  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:18  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:19  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:20  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:20  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:20  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:20  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:20  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:20  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:20  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:20  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:20  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:20  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:20  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:20  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:21  ->  10 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:21  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:21  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:21  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:21  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:23  ->  17 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:23  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:23  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:23  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:23  ->  Getting page: https://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:23  ->  18 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:23  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:23  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:23  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:24  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:24  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:24  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:24  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:24  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:24  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:24  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:24  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:24  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:24  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:24  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:24  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:24  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:24  ->  Getting page: https://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:25  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:25  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:25  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:25  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:25  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:25  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:25  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:25  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:25  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:25  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:25  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:25  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:25  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:25  ->  Getting page: https://books.toscrape.com/catalogue/category/books/business_35/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:26  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:26  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:26  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:26  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:26  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:26  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:26  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:26  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:26  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:26  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:26  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:26  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:26  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:26  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:26  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:26  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:26  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:26  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:27  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:27  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:27  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L314] - 2024-06-03 01:44:27  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:28  ->  Getting page: https://books.toscrape.com/catalogue/category/books/biography_36/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:28  ->  12 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:28  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:28  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:28  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:28  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:28  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:28  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:28  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:28  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:28  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:28  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:28  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:28  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:28  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:28  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:28  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:28  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:28  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:29  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:29  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:29  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:29  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:29  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:29  ->  Getting page: https://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-2.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:30  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:30  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:30  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:30  ->  Getting page: https://books.toscrape.com/catalogue/category/books/thriller_37/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:30  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:30  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:30  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:30  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:30  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:31  ->  Getting page: https://books.toscrape.com/catalogue/category/books/contemporary_38/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:31  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:31  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:31  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:31  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:31  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:31  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:31  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:31  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:31  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:31  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:31  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:31  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:31  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:32  ->  3 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:32  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:32  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:32  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:32  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:32  ->  10 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:32  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:32  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:32  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:32  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:33  ->  11 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:33  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:33  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:33  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:33  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/spirituality_39/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:34  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:34  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:34  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:34  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:34  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:34  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:34  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:34  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:34  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:34  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:34  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:34  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:34  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/academic_40/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:35  ->  Getting page: https://books.toscrape.com/catalogue/category/books/self-help_41/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:35  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:35  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:35  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:35  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:35  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:35  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:35  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:35  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:35  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:35  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:35  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:35  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:35  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:35  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:35  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:35  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:35  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:35  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:35  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:35  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:35  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:35  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:35  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:36  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:36  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:36  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:36  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:36  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:36  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:36  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:36  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:36  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:36  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:36  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:36  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:36  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:36  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:36  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:36  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:36  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:36  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:37  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical_42/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:37  ->  Getting page: https://books.toscrape.com/catalogue/category/books/christian_43/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:37  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:37  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:37  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:37  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:37  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:37  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:37  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:37  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:37  ->  2 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:37  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:37  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:37  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:37  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:38  ->  3 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:38  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:38  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:38  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:38  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/suspense_44/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:38  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:38  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:38  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:38  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:38  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:38  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:38  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:38  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:38  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:38  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:38  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:38  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:38  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:39  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:39  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:39  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:39  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:39  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/short-stories_45/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:40  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:40  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:40  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:40  ->  Getting page: https://books.toscrape.com/catalogue/category/books/novels_46/index.html
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:40  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:40  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:40  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:40  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:40  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:40  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:40  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:40  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:40  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:40  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:40  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:40  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:40  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:41  ->  Getting page: https://books.toscrape.com/catalogue/category/books/health_47/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:41  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:41  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:41  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:41  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:41  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:41  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:41  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:41  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:41  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:41  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:41  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:41  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:41  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:41  ->  4 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:41  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:41  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:41  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:41  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:42  ->  Getting page: https://books.toscrape.com/catalogue/category/books/politics_48/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:42  ->  Getting page: https://books.toscrape.com/catalogue/category/books/cultural_49/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:42  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:42  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:42  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:42  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:42  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:42  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:42  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:42  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:42  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:42  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:42  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:42  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:43  ->  3 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:43  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:43  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:43  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:43  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L456] - 2024-06-03 01:44:43  ->  Worker-2 completed task in time:  134.70s
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:43  ->  Getting page: https://books.toscrape.com/catalogue/category/books/erotica_50/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:44  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:44  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:44  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:44  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:44  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:44  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:44  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:44  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:44  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:44  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:44  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:44  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:44  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:44  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:44  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:44  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:44  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:44  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L456] - 2024-06-03 01:44:44  ->  Worker-3 completed task in time:  136.04s
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 01:44:45  ->  Getting page: https://books.toscrape.com/catalogue/category/books/crime_51/index.html
[INFO|beautifulCrawler|WEB_SCRAPER|L243] - 2024-06-03 01:44:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L356] - 2024-06-03 01:44:45  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:45  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:45  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:45  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:45  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:45  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:45  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:45  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:45  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L372] - 2024-06-03 01:44:45  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 01:44:45  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L378] - 2024-06-03 01:44:45  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L204] - 2024-06-03 01:44:45  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L385] - 2024-06-03 01:44:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L303] - 2024-06-03 01:44:45  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L226] - 2024-06-03 01:44:45  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L227] - 2024-06-03 01:44:45  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L456] - 2024-06-03 01:44:45  ->  Worker-1 completed task in time:  137.16s
[INFO|beautifulCrawler|WEB_SCRAPER|L424] - 2024-06-03 01:44:45  ->  Process completed in time:  137.17s
[INFO|utils|numexpr.utils|L160] - 2024-06-03 11:12:22  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 11:12:35  ->  Using proactor: IocpProactor
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 11:12:35  ->  Using proactor: IocpProactor
[INFO|beautifulCrawler|WEB_SCRAPER|L393] - 2024-06-03 11:12:35  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L401] - 2024-06-03 11:12:35  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L453] - 2024-06-03 11:12:35  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L453] - 2024-06-03 11:12:35  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L453] - 2024-06-03 11:12:35  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 11:12:37  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 11:12:38  ->  Getting page: https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L65] - 2024-06-03 11:12:38  ->  Getting page: https://books.toscrape.com
[ERROR|beautifulCrawler|WEB_SCRAPER|L73] - 2024-06-03 11:12:38  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L74] - 2024-06-03 11:12:38  ->  Exception: ClientConnectorError: Cannot connect to host books.toscrape.com:443 ssl:default [getaddrinfo failed]
[INFO|beautifulCrawler|WEB_SCRAPER|L457] - 2024-06-03 11:12:38  ->  Worker-1 completed task in time:  3.00s
[ERROR|beautifulCrawler|WEB_SCRAPER|L73] - 2024-06-03 11:12:38  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L74] - 2024-06-03 11:12:38  ->  Exception: ClientConnectorError: Cannot connect to host books.toscrape.com:443 ssl:default [getaddrinfo failed]
[INFO|beautifulCrawler|WEB_SCRAPER|L457] - 2024-06-03 11:12:38  ->  Worker-2 completed task in time:  3.01s
[ERROR|beautifulCrawler|WEB_SCRAPER|L73] - 2024-06-03 11:12:38  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L74] - 2024-06-03 11:12:38  ->  Exception: ClientConnectorError: Cannot connect to host books.toscrape.com:443 ssl:default [getaddrinfo failed]
[INFO|beautifulCrawler|WEB_SCRAPER|L457] - 2024-06-03 11:12:38  ->  Worker-3 completed task in time:  3.01s
[INFO|beautifulCrawler|WEB_SCRAPER|L425] - 2024-06-03 11:12:38  ->  Process completed in time:  3.02s
[INFO|utils|numexpr.utils|L160] - 2024-06-03 21:43:05  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:43:16  ->  Using proactor: IocpProactor
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:43:17  ->  Using proactor: IocpProactor
[INFO|utils|numexpr.utils|L160] - 2024-06-03 21:44:37  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:44:39  ->  Using proactor: IocpProactor
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:44:39  ->  Using proactor: IocpProactor
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 21:44:39  ->  Connecting to database mysql
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:44:40  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 21:44:40  ->  Successfully Connected to database!
[DEBUG|_config|httpx|L80] - 2024-06-03 21:44:40  ->  load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|httpx|L146] - 2024-06-03 21:44:40  ->  load_verify_locations cafile='C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\Library\\ssl\\cacert.pem'
[INFO|beautifulCrawler|WEB_SCRAPER|L410] - 2024-06-03 21:44:41  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L418] - 2024-06-03 21:44:41  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L470] - 2024-06-03 21:44:41  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L470] - 2024-06-03 21:44:41  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L470] - 2024-06-03 21:44:41  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:44:43  ->  Getting page: https://books.toscrape.com
[ERROR|beautifulCrawler|WEB_SCRAPER|L90] - 2024-06-03 21:44:43  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L91] - 2024-06-03 21:44:43  ->  Exception: TypeError: get() got an unexpected keyword argument 'allow_redirects'
[INFO|beautifulCrawler|WEB_SCRAPER|L477] - 2024-06-03 21:44:43  ->  Worker-1 completed task in time:  2.01s
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:44:43  ->  Getting page: https://books.toscrape.com
[ERROR|beautifulCrawler|WEB_SCRAPER|L90] - 2024-06-03 21:44:43  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L91] - 2024-06-03 21:44:43  ->  Exception: TypeError: get() got an unexpected keyword argument 'allow_redirects'
[INFO|beautifulCrawler|WEB_SCRAPER|L477] - 2024-06-03 21:44:43  ->  Worker-2 completed task in time:  2.02s
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:44:43  ->  Getting page: https://books.toscrape.com
[ERROR|beautifulCrawler|WEB_SCRAPER|L90] - 2024-06-03 21:44:43  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L91] - 2024-06-03 21:44:43  ->  Exception: TypeError: get() got an unexpected keyword argument 'allow_redirects'
[INFO|beautifulCrawler|WEB_SCRAPER|L477] - 2024-06-03 21:44:43  ->  Worker-3 completed task in time:  2.04s
[INFO|beautifulCrawler|WEB_SCRAPER|L442] - 2024-06-03 21:44:43  ->  Process completed in time:  2.06s
[INFO|utils|numexpr.utils|L160] - 2024-06-03 21:45:43  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:45:44  ->  Using proactor: IocpProactor
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:45:44  ->  Using proactor: IocpProactor
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 21:45:44  ->  Connecting to database mysql
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:45:44  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 21:45:44  ->  Successfully Connected to database!
[DEBUG|_config|httpx|L80] - 2024-06-03 21:45:44  ->  load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|httpx|L146] - 2024-06-03 21:45:44  ->  load_verify_locations cafile='C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\Library\\ssl\\cacert.pem'
[INFO|beautifulCrawler|WEB_SCRAPER|L411] - 2024-06-03 21:45:45  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L419] - 2024-06-03 21:45:45  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L471] - 2024-06-03 21:45:45  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L471] - 2024-06-03 21:45:45  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L471] - 2024-06-03 21:45:45  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:45:47  ->  Getting page: https://books.toscrape.com
[ERROR|beautifulCrawler|WEB_SCRAPER|L91] - 2024-06-03 21:45:47  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L92] - 2024-06-03 21:45:47  ->  Exception: TypeError: log_request() takes 1 positional argument but 2 were given
[INFO|beautifulCrawler|WEB_SCRAPER|L478] - 2024-06-03 21:45:47  ->  Worker-1 completed task in time:  2.03s
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:45:47  ->  Getting page: https://books.toscrape.com
[ERROR|beautifulCrawler|WEB_SCRAPER|L91] - 2024-06-03 21:45:47  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L92] - 2024-06-03 21:45:47  ->  Exception: TypeError: log_request() takes 1 positional argument but 2 were given
[INFO|beautifulCrawler|WEB_SCRAPER|L478] - 2024-06-03 21:45:47  ->  Worker-2 completed task in time:  2.03s
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:45:47  ->  Getting page: https://books.toscrape.com
[ERROR|beautifulCrawler|WEB_SCRAPER|L91] - 2024-06-03 21:45:47  ->  Unable to get page!!!
[ERROR|beautifulCrawler|WEB_SCRAPER|L92] - 2024-06-03 21:45:47  ->  Exception: TypeError: log_request() takes 1 positional argument but 2 were given
[INFO|beautifulCrawler|WEB_SCRAPER|L478] - 2024-06-03 21:45:47  ->  Worker-3 completed task in time:  2.04s
[INFO|beautifulCrawler|WEB_SCRAPER|L443] - 2024-06-03 21:45:47  ->  Process completed in time:  2.06s
[INFO|utils|numexpr.utils|L160] - 2024-06-03 21:46:29  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:46:31  ->  Using proactor: IocpProactor
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:46:31  ->  Using proactor: IocpProactor
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 21:46:31  ->  Connecting to database mysql
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:46:31  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 21:46:31  ->  Successfully Connected to database!
[DEBUG|_config|httpx|L80] - 2024-06-03 21:46:31  ->  load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|httpx|L146] - 2024-06-03 21:46:31  ->  load_verify_locations cafile='C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\Library\\ssl\\cacert.pem'
[INFO|beautifulCrawler|WEB_SCRAPER|L411] - 2024-06-03 21:46:32  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L419] - 2024-06-03 21:46:32  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L471] - 2024-06-03 21:46:32  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L471] - 2024-06-03 21:46:32  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L471] - 2024-06-03 21:46:32  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:46:34  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:46:34  ->  Request: GET https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:46:34  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:46:34  ->  Request: GET https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:46:34  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:46:34  ->  Request: GET https://books.toscrape.com
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:34  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:34  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:34  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DEE25A01F0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DEE2523840> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DEE255BCD0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DEE2523840> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DEE25D3370>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DEE2523840> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DEE25D3550>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DEE25A0070>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:36  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DEE25CD370>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:47:08 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:46:36  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:46:36  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:47:08 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:46:36  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:46:36  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:47:08 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:46:36  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:46:36  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  response_closed.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  response_closed.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:36  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:46:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:46:38  ->  Request: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:46:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:46:38  ->  Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:38  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:46:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:46:39  ->  Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:47:10 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-9091"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:46:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:46:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:47:10 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c4d4"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:46:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:46:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:47:10 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c3bd"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:46:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:46:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:46:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:46:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:46:39  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:46:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:46:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:46:39  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:46:39  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:46:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:46:40  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:40  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:40  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:40  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:40  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:40  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:46:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:46:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:46:40  ->  saving data to db storage: BookScrape
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:46:40  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:46:40  ->  caching sha2: succeeded by fast path.
[INFO|beautifulCrawler|WEB_SCRAPER|L443] - 2024-06-03 21:46:44  ->  Process completed in time:  12.44s
[ERROR|base_events|asyncio|L1753] - 2024-06-03 21:46:44  ->  Task exception was never retrieved
future: <Task finished name='Task-4' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:448> exception=RuntimeError("Task <Task pending name='Task-4' coro=<Crawler.task() running at c:\\Users\\rm\\Desktop\\Scraping Template\\Beautiful\\Web Scraping custom Template\\beautifulCrawler.py:476> cb=[_wait.<locals>._on_completion() at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\asyncio\\tasks.py:509]> got Future <Task pending name='Task-10' coro=<Pool._wakeup() running at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\site-packages\\aiomysql\\pool.py:203>> attached to a different loop")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 476, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 361, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 307, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 294, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 397, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 205, in insert_data
    inserted_records += 1
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\utils.py", line 139, in __aexit__
    await self._pool.release(self._conn)
RuntimeError: Task <Task pending name='Task-4' coro=<Crawler.task() running at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:476> cb=[_wait.<locals>._on_completion() at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\asyncio\tasks.py:509]> got Future <Task pending name='Task-10' coro=<Pool._wakeup() running at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\pool.py:203>> attached to a different loop
[ERROR|base_events|asyncio|L1753] - 2024-06-03 21:46:44  ->  Task exception was never retrieved
future: <Task finished name='Task-3' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:448> exception=RuntimeError("Task <Task pending name='Task-3' coro=<Crawler.task() running at c:\\Users\\rm\\Desktop\\Scraping Template\\Beautiful\\Web Scraping custom Template\\beautifulCrawler.py:476> cb=[_wait.<locals>._on_completion() at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\asyncio\\tasks.py:509]> got Future <Task pending name='Task-8' coro=<Pool._wakeup() running at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\site-packages\\aiomysql\\pool.py:203>> attached to a different loop")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 476, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 361, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 307, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 294, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 397, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 205, in insert_data
    inserted_records += 1
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\utils.py", line 139, in __aexit__
    await self._pool.release(self._conn)
RuntimeError: Task <Task pending name='Task-3' coro=<Crawler.task() running at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:476> cb=[_wait.<locals>._on_completion() at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\asyncio\tasks.py:509]> got Future <Task pending name='Task-8' coro=<Pool._wakeup() running at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\pool.py:203>> attached to a different loop
[ERROR|base_events|asyncio|L1753] - 2024-06-03 21:46:44  ->  Task exception was never retrieved
future: <Task finished name='Task-2' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:448> exception=RuntimeError("Task <Task pending name='Task-2' coro=<Crawler.task() running at c:\\Users\\rm\\Desktop\\Scraping Template\\Beautiful\\Web Scraping custom Template\\beautifulCrawler.py:476> cb=[_wait.<locals>._on_completion() at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\asyncio\\tasks.py:509]> got Future <Task pending name='Task-9' coro=<Pool._wakeup() running at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\site-packages\\aiomysql\\pool.py:203>> attached to a different loop")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 476, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 361, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 307, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 294, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 397, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 205, in insert_data
    inserted_records += 1
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\utils.py", line 139, in __aexit__
    await self._pool.release(self._conn)
RuntimeError: Task <Task pending name='Task-2' coro=<Crawler.task() running at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:476> cb=[_wait.<locals>._on_completion() at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\asyncio\tasks.py:509]> got Future <Task pending name='Task-9' coro=<Pool._wakeup() running at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\pool.py:203>> attached to a different loop
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:44  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:44  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:44  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:44  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:44  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:46:44  ->  close.complete
[INFO|utils|numexpr.utils|L160] - 2024-06-03 21:50:02  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:50:03  ->  Using proactor: IocpProactor
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:50:04  ->  Using proactor: IocpProactor
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 21:50:04  ->  Connecting to database mysql
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:50:04  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 21:50:04  ->  Successfully Connected to database!
[DEBUG|_config|httpx|L80] - 2024-06-03 21:50:04  ->  load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|httpx|L146] - 2024-06-03 21:50:04  ->  load_verify_locations cafile='C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\Library\\ssl\\cacert.pem'
[INFO|beautifulCrawler|WEB_SCRAPER|L411] - 2024-06-03 21:50:04  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L419] - 2024-06-03 21:50:04  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L472] - 2024-06-03 21:50:04  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L472] - 2024-06-03 21:50:04  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L472] - 2024-06-03 21:50:04  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:50:06  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:50:06  ->  Request: GET https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:50:06  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:50:06  ->  Request: GET https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:50:06  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:50:06  ->  Request: GET https://books.toscrape.com
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:06  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:06  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:06  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002A8368CFA90>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002A836822940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002A836873DC0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002A836822940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002A836800BE0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002A836822940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002A8368D4640>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002A836873C40>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:07  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002A8368D4820>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:50:39 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:50:07  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:50:07  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:50:39 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:50:07  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:50:07  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:50:39 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:50:07  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:50:07  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  response_closed.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:07  ->  response_closed.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:08  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:08  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:08  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:50:09  ->  Getting page: https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:50:09  ->  Request: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:09  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:09  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:09  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:09  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:09  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:50:10  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:50:10  ->  Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:50:10  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:50:10  ->  Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:50:41 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-9091"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:50:10  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:50:10  ->  Response: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:50:41 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c4d4"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:50:10  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:50:10  ->  Response: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:50:41 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c3bd"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:50:10  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:50:10  ->  Response: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:50:10  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:50:10  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:50:10  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:50:10  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:50:10  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:50:10  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:50:10  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:50:10  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:50:10  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:50:10  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:50:10  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:50:10  ->  saving data to db storage: BookScrape
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:50:10  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:50:11  ->  caching sha2: succeeded by fast path.
[INFO|beautifulCrawler|WEB_SCRAPER|L444] - 2024-06-03 21:50:15  ->  Process completed in time:  11.10s
[ERROR|base_events|asyncio|L1753] - 2024-06-03 21:50:15  ->  Task exception was never retrieved
future: <Task finished name='Task-4' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:449> exception=RuntimeError("Task <Task pending name='Task-4' coro=<Crawler.task() running at c:\\Users\\rm\\Desktop\\Scraping Template\\Beautiful\\Web Scraping custom Template\\beautifulCrawler.py:477> cb=[_wait.<locals>._on_completion() at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\asyncio\\tasks.py:509]> got Future <Task pending name='Task-8' coro=<Pool._wakeup() running at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\site-packages\\aiomysql\\pool.py:203>> attached to a different loop")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 477, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 361, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 307, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 294, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 397, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 205, in insert_data
    inserted_records += 1
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\utils.py", line 139, in __aexit__
    await self._pool.release(self._conn)
RuntimeError: Task <Task pending name='Task-4' coro=<Crawler.task() running at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:477> cb=[_wait.<locals>._on_completion() at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\asyncio\tasks.py:509]> got Future <Task pending name='Task-8' coro=<Pool._wakeup() running at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\pool.py:203>> attached to a different loop
[ERROR|base_events|asyncio|L1753] - 2024-06-03 21:50:15  ->  Task exception was never retrieved
future: <Task finished name='Task-3' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:449> exception=RuntimeError("Task <Task pending name='Task-3' coro=<Crawler.task() running at c:\\Users\\rm\\Desktop\\Scraping Template\\Beautiful\\Web Scraping custom Template\\beautifulCrawler.py:477> cb=[_wait.<locals>._on_completion() at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\asyncio\\tasks.py:509]> got Future <Task pending name='Task-9' coro=<Pool._wakeup() running at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\site-packages\\aiomysql\\pool.py:203>> attached to a different loop")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 477, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 361, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 307, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 294, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 397, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 205, in insert_data
    inserted_records += 1
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\utils.py", line 139, in __aexit__
    await self._pool.release(self._conn)
RuntimeError: Task <Task pending name='Task-3' coro=<Crawler.task() running at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:477> cb=[_wait.<locals>._on_completion() at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\asyncio\tasks.py:509]> got Future <Task pending name='Task-9' coro=<Pool._wakeup() running at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\pool.py:203>> attached to a different loop
[ERROR|base_events|asyncio|L1753] - 2024-06-03 21:50:15  ->  Task exception was never retrieved
future: <Task finished name='Task-2' coro=<Crawler.task() done, defined at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:449> exception=RuntimeError("Task <Task pending name='Task-2' coro=<Crawler.task() running at c:\\Users\\rm\\Desktop\\Scraping Template\\Beautiful\\Web Scraping custom Template\\beautifulCrawler.py:477> cb=[_wait.<locals>._on_completion() at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\asyncio\\tasks.py:509]> got Future <Task pending name='Task-10' coro=<Pool._wakeup() running at C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\lib\\site-packages\\aiomysql\\pool.py:203>> attached to a different loop")>
Traceback (most recent call last):
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 477, in task
    await self.crawl(website)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 361, in crawl
    await self.parse(targetPage)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 307, in parse
    await self.parse_page_data(page)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 294, in parse_page_data
    await self.pipeline(dataset)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py", line 397, in pipeline
    await self.storage.insert_data(dataset.endpoint, df)
  File "c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\storage.py", line 205, in insert_data
    inserted_records += 1
  File "C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\utils.py", line 139, in __aexit__
    await self._pool.release(self._conn)
RuntimeError: Task <Task pending name='Task-2' coro=<Crawler.task() running at c:\Users\rm\Desktop\Scraping Template\Beautiful\Web Scraping custom Template\beautifulCrawler.py:477> cb=[_wait.<locals>._on_completion() at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\asyncio\tasks.py:509]> got Future <Task pending name='Task-10' coro=<Pool._wakeup() running at C:\Users\rm\anaconda3\envs\DataEngineeringEnv\lib\site-packages\aiomysql\pool.py:203>> attached to a different loop
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:15  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:15  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:15  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:15  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:15  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:50:15  ->  close.complete
[INFO|utils|numexpr.utils|L160] - 2024-06-03 21:52:31  ->  NumExpr defaulting to 4 threads.
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:52:33  ->  Using proactor: IocpProactor
[DEBUG|proactor_events|asyncio|L624] - 2024-06-03 21:52:33  ->  Using proactor: IocpProactor
[INFO|storage|WEB_SCRAPER|L78] - 2024-06-03 21:52:33  ->  Connecting to database mysql
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:52:33  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L91] - 2024-06-03 21:52:33  ->  Successfully Connected to database!
[DEBUG|_config|httpx|L80] - 2024-06-03 21:52:33  ->  load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|httpx|L146] - 2024-06-03 21:52:33  ->  load_verify_locations cafile='C:\\Users\\rm\\anaconda3\\envs\\DataEngineeringEnv\\Library\\ssl\\cacert.pem'
[INFO|beautifulCrawler|WEB_SCRAPER|L411] - 2024-06-03 21:52:34  ->  Gathering website configuration files...
[INFO|beautifulCrawler|WEB_SCRAPER|L419] - 2024-06-03 21:52:34  ->  Gathered 3 website files
[INFO|beautifulCrawler|WEB_SCRAPER|L472] - 2024-06-03 21:52:34  ->  Worker-1 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L472] - 2024-06-03 21:52:34  ->  Worker-2 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L472] - 2024-06-03 21:52:34  ->  Worker-3 starts task of crawling BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:36  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:36  ->  Request: GET https://books.toscrape.com
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:36  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:36  ->  Request: GET https://books.toscrape.com
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:36  ->  Getting page: https://books.toscrape.com
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:36  ->  Request: GET https://books.toscrape.com
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BDDE0A0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BDB3100>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BDFD160>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BDB30D0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BDDE220>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:36  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BD67D00>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:36  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:08 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:37  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:37  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:08 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:37  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:37  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:08 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c85e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:37  ->  HTTP Request: GET https://books.toscrape.com "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:37  ->  Response: GET https://books.toscrape.com - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  response_closed.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  response_closed.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:37  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:39  ->  Request: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:39  ->  Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:39  ->  Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:11 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-9091"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/travel_2/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:11 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c4d4"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/mystery_3/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:11 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c3bd"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:39  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:39  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:40  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:40  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:40  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:40  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:40  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:40  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:40  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:40  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:40  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:40  ->  saving data to db storage: BookScrape
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:52:40  ->  caching sha2: succeeded by fast path.
[DEBUG|connection|aiomysql|L951] - 2024-06-03 21:52:40  ->  caching sha2: succeeded by fast path.
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:42  ->  11 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:42  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:42  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:52:42  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:52:42  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:44  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:44  ->  Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:44  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:44  ->  close.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:44  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:44  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:44  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:44  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:44  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:45  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:45  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:52:45  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:45  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:45  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:52:45  ->  going to next page
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:45  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:16 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c8ff"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:45  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:45  ->  Response: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:45  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:45  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:45  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:45  ->  response_closed.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:45  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:45  ->  close.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:45  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:45  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:45  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:45  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:45  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:45  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:45  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:45  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:45  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:45  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:45  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:45  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:47  ->  Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/page-2.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:47  ->  Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:47  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:18 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-7157"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:47  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:47  ->  Response: GET https://books.toscrape.com/catalogue/category/books/historical-fiction_4/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:47  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:47  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:47  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:47  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:47  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:47  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:47  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:47  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:47  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:47  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:47  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:47  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:47  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:47  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C19C8B0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:47  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:47  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C2F8F40>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:19 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-9685"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:47  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:47  ->  Response: GET https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:47  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:48  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:48  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:48  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:48  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:48  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:48  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:48  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:48  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:48  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:48  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:48  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:48  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:48  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:48  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:48  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:48  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:48  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:48  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:52:48  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:52:48  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:49  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:49  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:49  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:52:49  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/classics_6/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:50  ->  Request: GET https://books.toscrape.com/catalogue/category/books/classics_6/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:50  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:50  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:50  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:50  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:50  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:50  ->  12 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:50  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:50  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:52:50  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:52:50  ->  Moving on!
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:22 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-bb02"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:51  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/classics_6/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:51  ->  Response: GET https://books.toscrape.com/catalogue/category/books/classics_6/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:51  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:51  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:51  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:51  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:51  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:51  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:51  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:51  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:51  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:51  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:51  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:51  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:51  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:51  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:51  ->  Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-2.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:51  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:23 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c7dd"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:52  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:52  ->  Response: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:52  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:52  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:52  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:52  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:52  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:52  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:52  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:52  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:52  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:52  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:52  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:52  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:52  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:52  ->  Getting page: https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:52  ->  Request: GET https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:52  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:53  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:24 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-90a8"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:52:53  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:52:53  ->  Response: GET https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:53  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:53  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:53  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:52:53  ->  response_closed.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:53  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:53  ->  close.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:52:53  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:52:53  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:53  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:53  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:53  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:53  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:53  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:53  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:53  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:53  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:52:53  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:52:53  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:52:53  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:57  ->  19 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:57  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:57  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:52:57  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:52:57  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:57  ->  11 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:57  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:57  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:52:57  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:52:57  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:52:58  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:52:58  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:52:58  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:52:58  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:59  ->  Getting page: https://books.toscrape.com/catalogue/category/books/romance_8/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:59  ->  Request: GET https://books.toscrape.com/catalogue/category/books/romance_8/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:59  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:59  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:59  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:52:59  ->  Getting page: https://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:52:59  ->  Request: GET https://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:52:59  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:00  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C37C400>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:00  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:00  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C4587C0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:00  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:00  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BED6130>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:00  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C458E50>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:32 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-b0fc"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:00  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:00  ->  Response: GET https://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:32 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c4dd"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:00  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/romance_8/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:00  ->  Response: GET https://books.toscrape.com/catalogue/category/books/romance_8/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:00  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:00  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:00  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:00  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:00  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:00  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:00  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:00  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:00  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:00  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:00  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:00  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:00  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:00  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:01  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:01  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-3.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:01  ->  Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-3.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:33 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c8c0"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:01  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-3.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:01  ->  Response: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-3.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:01  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:01  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:01  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:01  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:01  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:01  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:09  ->  17 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:09  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:09  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:09  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:09  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:10  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:10  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:10  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:10  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:10  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:10  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:10  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:10  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:11  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:11  ->  Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:11  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:11  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:11  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:11  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:11  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:11  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C363E20>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:11  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:12  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C0A5460>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:43 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c20d"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:12  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:12  ->  Response: GET https://books.toscrape.com/catalogue/category/books/fiction_10/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:12  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:12  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:12  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:12  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:12  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:12  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:12  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:12  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:12  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:12  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:12  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:12  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:12  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:12  ->  Getting page: https://books.toscrape.com/catalogue/category/books/romance_8/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:12  ->  Request: GET https://books.toscrape.com/catalogue/category/books/romance_8/page-2.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:12  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:13  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-4.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:13  ->  Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-4.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:13  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:44 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-a68c"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:13  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/romance_8/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:13  ->  Response: GET https://books.toscrape.com/catalogue/category/books/romance_8/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:13  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:13  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:13  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:13  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:13  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:13  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:13  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:13  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:13  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:13  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:13  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:13  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:13  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:13  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C0B3730>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:13  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:13  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C593F70>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:45 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-ab40"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:13  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-4.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:13  ->  Response: GET https://books.toscrape.com/catalogue/category/books/sequential-art_5/page-4.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:13  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:14  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:14  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:14  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:14  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:14  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:14  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:14  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:14  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:14  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:14  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:14  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:14  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:14  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:17  ->  15 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:17  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:17  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:17  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:17  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:18  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:18  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:18  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:18  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:18  ->  15 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:18  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:18  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:18  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:18  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:19  ->  Getting page: https://books.toscrape.com/catalogue/category/books/childrens_11/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:19  ->  Request: GET https://books.toscrape.com/catalogue/category/books/childrens_11/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:19  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:19  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:19  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:19  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:19  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:19  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C5932E0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:19  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:20  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:20  ->  Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-2.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:20  ->  Getting page: https://books.toscrape.com/catalogue/category/books/religion_12/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:20  ->  Request: GET https://books.toscrape.com/catalogue/category/books/religion_12/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C593280>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C6B94C0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C588CA0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:52 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c2c8"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:20  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/childrens_11/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:20  ->  Response: GET https://books.toscrape.com/catalogue/category/books/childrens_11/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C0B3220>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:20  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:20  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:20  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:20  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:20  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:20  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:20  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:20  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:20  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:20  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:20  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:20  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:20  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:52 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c166"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:20  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:20  ->  Response: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:20  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C6B9CD0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:20  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:21  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:21  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:21  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:52 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-78d5"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:21  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/religion_12/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:21  ->  Response: GET https://books.toscrape.com/catalogue/category/books/religion_12/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:21  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:21  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:21  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:21  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:21  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:21  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:23  ->  7 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:23  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:23  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:23  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:25  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:25  ->  Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:25  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:25  ->  close.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:25  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:25  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:25  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:25  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:25  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:26  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:53:57 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-cdf5"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:26  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:26  ->  Response: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:26  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:26  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:26  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:26  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:26  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:26  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:26  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:26  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:26  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:26  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:26  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:26  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:26  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:26  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:26  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:26  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:26  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:26  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:26  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:26  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:26  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:27  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:27  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:27  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:27  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:28  ->  Getting page: https://books.toscrape.com/catalogue/category/books/childrens_11/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:28  ->  Request: GET https://books.toscrape.com/catalogue/category/books/childrens_11/page-2.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:28  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:28  ->  close.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:28  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:28  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:28  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:28  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:28  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:29  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-3.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:29  ->  Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-3.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:29  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:00 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-83fc"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:29  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/childrens_11/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:29  ->  Response: GET https://books.toscrape.com/catalogue/category/books/childrens_11/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:29  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:29  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:29  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:29  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:29  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:29  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:29  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:29  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:29  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:29  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:29  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:29  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:29  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:29  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C880F40>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:29  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:29  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C817FA0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:01 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c12d"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:29  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-3.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:29  ->  Response: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-3.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:29  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:30  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:30  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:30  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:30  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:30  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:30  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:30  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:30  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:30  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:30  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:30  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:30  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:30  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:30  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:30  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:30  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:30  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:30  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:30  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:30  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:31  ->  9 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:31  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:31  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:31  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:31  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:32  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:32  ->  Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-2.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:32  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:32  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:32  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:32  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:32  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:04 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-ccf0"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:33  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:33  ->  Response: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:33  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:33  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:33  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:33  ->  Getting page: https://books.toscrape.com/catalogue/category/books/music_14/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:33  ->  Request: GET https://books.toscrape.com/catalogue/category/books/music_14/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:05 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-9d01"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:33  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/music_14/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:33  ->  Response: GET https://books.toscrape.com/catalogue/category/books/music_14/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:33  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:33  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:33  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:33  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:33  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:33  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:33  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:33  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:33  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:33  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:35  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fiction_10/page-4.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:35  ->  Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-4.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:35  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:35  ->  close.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:35  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:35  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:35  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:36  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:36  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:36  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:07 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-6b20"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:36  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-4.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:36  ->  Response: GET https://books.toscrape.com/catalogue/category/books/fiction_10/page-4.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:36  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:36  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:36  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:36  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:36  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:36  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:36  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:36  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:36  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:36  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:36  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:36  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:36  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:36  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:36  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:36  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:36  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:36  ->  13 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:36  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:36  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:36  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:36  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:37  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:37  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:37  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:37  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:37  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:37  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:37  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:37  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:37  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:38  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:38  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:38  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:38  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:38  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:38  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:38  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:10 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c912"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:39  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:39  ->  Request: GET https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:11 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-ad9f"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:39  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:39  ->  Response: GET https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:39  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:39  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:39  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:39  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:39  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:39  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-3.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:39  ->  Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-3.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:39  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:40  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:11 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-ccb1"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:40  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-3.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:40  ->  Response: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-3.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:40  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:40  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:40  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:40  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:40  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:40  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:40  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:40  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:40  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:40  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:40  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:40  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:40  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:40  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:40  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:40  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:40  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:43  ->  16 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:43  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:43  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:43  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:43  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:43  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:43  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:43  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:43  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:44  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:44  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:44  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:44  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:45  ->  Getting page: https://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:45  ->  Request: GET https://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:45  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:45  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:45  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:45  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:45  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-2.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:45  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:45  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CABA730>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:45  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:46  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C817FD0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:46  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:46  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CBACF10>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:46  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-4.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:46  ->  Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-4.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:46  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:18 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-6ba6"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:46  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:46  ->  Response: GET https://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:46  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:46  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:46  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:46  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:46  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:46  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:46  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:46  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:46  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:46  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:46  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:46  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:46  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:46  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CBB65B0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:18 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c6aa"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:46  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:46  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:46  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:46  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C8804C0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:46  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:47  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:47  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:47  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:47  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CCFDE80>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:19 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-cd3a"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:47  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-4.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:47  ->  Response: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-4.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:47  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:47  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:47  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:47  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:47  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:47  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:47  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:47  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:47  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:53:47  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:53:47  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:49  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:49  ->  Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:49  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:49  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:49  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:49  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:49  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:50  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:21 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c6f3"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:50  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:50  ->  Response: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:50  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:50  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:50  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:50  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:50  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:50  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:50  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:50  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:50  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:50  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:50  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:50  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:50  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:50  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:50  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:50  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:50  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:53  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:53  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:53  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:53  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:53  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:53  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:53:55  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:53:55  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:53:55  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:53:55  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-3.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:55  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-3.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-5.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:55  ->  Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-5.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CC4A6A0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:55  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:56  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CEB3BB0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:56  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:56  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CC4A4F0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:53:56  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CBACA30>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:28 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c688"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:56  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-3.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:56  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/page-3.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:56  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:56  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:56  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:56  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:56  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:56  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:56  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:56  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:56  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:56  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:56  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:56  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:56  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:28 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-cb93"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:56  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-5.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:56  ->  Response: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-5.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:56  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:57  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:57  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:57  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:53:57  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:53:57  ->  Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-2.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:29 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c3c7"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:53:57  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:53:57  ->  Response: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:53:57  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:53:57  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:53:57  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:53:57  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:53:57  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:53:57  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:02  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:02  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:02  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:03  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:03  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:03  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:03  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:03  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:03  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:03  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:03  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:03  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:05  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-4.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:05  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-4.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:05  ->  Getting page: https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-6.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:05  ->  Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-6.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CF67D90>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C6C5250>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:05  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-3.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:05  ->  Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-3.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C6C5490>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C6C5B50>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BDFD5E0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:05  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:37 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c816"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:05  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-4.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:05  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/page-4.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:37 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-8a25"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:05  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-6.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:05  ->  Response: GET https://books.toscrape.com/catalogue/category/books/nonfiction_13/page-6.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:05  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:06  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CF67F70>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:06  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:06  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:06  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:06  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:06  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:06  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:37 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c730"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:06  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-3.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:06  ->  Response: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-3.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:06  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:06  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:06  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:06  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:06  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:06  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:09  ->  10 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:09  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:09  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:09  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:09  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:11  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:11  ->  Request: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:11  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:11  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:11  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:11  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:11  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:11  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:11  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:11  ->  going to next page
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:43 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c830"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:11  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:11  ->  Response: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:11  ->  response_closed.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:11  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:11  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:11  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:11  ->  close.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:11  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:11  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:11  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:11  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:11  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:11  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:11  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:12  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:12  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:12  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:12  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:12  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:12  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:13  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-5.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:13  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-5.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:13  ->  Getting page: https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-4.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:13  ->  Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-4.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:13  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:45 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c753"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:13  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-5.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:13  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/page-5.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:13  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BDFD280>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:13  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:13  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:13  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:13  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:13  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:13  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:13  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:13  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:13  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:13  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:13  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:13  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:13  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:13  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:13  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:14  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092BE060D0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:45 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-7659"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:14  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-4.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:14  ->  Response: GET https://books.toscrape.com/catalogue/category/books/add-a-comment_18/page-4.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:14  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:14  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:14  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:14  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:14  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:14  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:14  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:14  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:14  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:14  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:14  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:14  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:14  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:14  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:15  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:15  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:15  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:15  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:15  ->  7 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:15  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:15  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:15  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:15  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:17  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:17  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:17  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:17  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:17  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:17  ->  Request: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/page-2.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:17  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:17  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:17  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:17  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:17  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:17  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:49 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c68f"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:17  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:17  ->  Response: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:17  ->  receive_response_body.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:17  ->  Getting page: https://books.toscrape.com/catalogue/category/books/new-adult_20/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:18  ->  Request: GET https://books.toscrape.com/catalogue/category/books/new-adult_20/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:18  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:18  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:18  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:49 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-703c"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:18  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/new-adult_20/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:18  ->  Response: GET https://books.toscrape.com/catalogue/category/books/new-adult_20/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:18  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:18  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:18  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:18  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:18  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:18  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:19  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-6.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:19  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-6.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:19  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:19  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:19  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:19  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:19  ->  Moving on!
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:51 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c498"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:19  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-6.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:19  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/page-6.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:19  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:20  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:20  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:20  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:20  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:20  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:20  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:20  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:20  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:20  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:20  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:20  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:20  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:20  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:21  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:21  ->  Request: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:21  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:21  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:21  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:21  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:21  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:21  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:21  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:21  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:21  ->  going to next page
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:21  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:53 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c3f7"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:21  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:21  ->  Response: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:21  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:22  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:22  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:22  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:22  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:22  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:22  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:22  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:22  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:22  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:22  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:22  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:22  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:22  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:22  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:22  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:22  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:23  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:23  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:23  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:23  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:23  ->  Getting page: https://books.toscrape.com/catalogue/category/books/fantasy_19/page-3.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:23  ->  Request: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/page-3.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:23  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:23  ->  close.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:55 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-7dd2"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:23  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/page-3.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:23  ->  Response: GET https://books.toscrape.com/catalogue/category/books/fantasy_19/page-3.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:23  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:23  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:24  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:24  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:24  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:24  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:24  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:24  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:24  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:24  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:24  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:24  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:24  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:24  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:25  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-7.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:25  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-7.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:25  ->  8 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:25  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:25  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:25  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:25  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:25  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:25  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:25  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:25  ->  going to next page
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:57 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c5ec"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:25  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-7.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:25  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/page-7.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:25  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:26  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:26  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:26  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:26  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:26  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:26  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:26  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:26  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:26  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:26  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:26  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:26  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:26  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:27  ->  Getting page: https://books.toscrape.com/catalogue/category/books/science_22/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:27  ->  Request: GET https://books.toscrape.com/catalogue/category/books/science_22/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:27  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:27  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:27  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:27  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:27  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:27  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:27  ->  Request: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/page-2.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:27  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:27  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:54:59 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-a633"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:27  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/science_22/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:27  ->  Response: GET https://books.toscrape.com/catalogue/category/books/science_22/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:27  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:27  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C1072B0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:27  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:28  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:28  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:28  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:28  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CC32DC0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:00 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c45c"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:28  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:28  ->  Response: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:28  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:28  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:28  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:28  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:28  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:28  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:31  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:31  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:31  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:32  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:32  ->  14 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:32  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:32  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:32  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:32  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:33  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:33  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:33  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:54:33  ->  going to next page
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/default_15/page-8.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:34  ->  Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-8.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:34  ->  Getting page: https://books.toscrape.com/catalogue/category/books/poetry_23/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:34  ->  Request: GET https://books.toscrape.com/catalogue/category/books/poetry_23/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C7F5F10>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C4B6760>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CD08220>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:34  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092CD08100>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:34  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:06 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-bc4f"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:35  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/poetry_23/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:35  ->  Response: GET https://books.toscrape.com/catalogue/category/books/poetry_23/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:35  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:35  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:35  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:35  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:35  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:35  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:35  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:35  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:35  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:35  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:35  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:35  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:35  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:35  ->  Getting page: https://books.toscrape.com/catalogue/category/books/young-adult_21/page-3.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:35  ->  Request: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/page-3.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:07 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-9417"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:35  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/default_15/page-8.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:35  ->  Response: GET https://books.toscrape.com/catalogue/category/books/default_15/page-8.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:35  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:07 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-9fbd"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:36  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/page-3.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:36  ->  Response: GET https://books.toscrape.com/catalogue/category/books/young-adult_21/page-3.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:36  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:36  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:36  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:36  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:36  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:36  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:36  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:36  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:36  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:40  ->  12 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:40  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:40  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:40  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:40  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:41  ->  14 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:41  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:41  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:41  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:41  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:41  ->  19 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:41  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:41  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:41  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:41  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:42  ->  Getting page: https://books.toscrape.com/catalogue/category/books/paranormal_24/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:42  ->  Request: GET https://books.toscrape.com/catalogue/category/books/paranormal_24/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  close.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C7A1D90>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:42  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C7A1520>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:42  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:42  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:42  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:42  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:42  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:14 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-5389"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:43  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/paranormal_24/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:43  ->  Response: GET https://books.toscrape.com/catalogue/category/books/paranormal_24/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:43  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:43  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:43  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:43  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:43  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:43  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:43  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:43  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:43  ->  Getting page: https://books.toscrape.com/catalogue/category/books/art_25/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:43  ->  Request: GET https://books.toscrape.com/catalogue/category/books/art_25/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:15 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-7c19"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:43  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/art_25/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:43  ->  Response: GET https://books.toscrape.com/catalogue/category/books/art_25/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:43  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:43  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:43  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:43  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:43  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:43  ->  Getting page: https://books.toscrape.com/catalogue/category/books/psychology_26/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:43  ->  Request: GET https://books.toscrape.com/catalogue/category/books/psychology_26/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:43  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:44  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:15 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-78f8"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:44  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/psychology_26/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:44  ->  Response: GET https://books.toscrape.com/catalogue/category/books/psychology_26/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:44  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:44  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:44  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:44  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:44  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:44  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:44  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:44  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:44  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:44  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:44  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:44  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:44  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:44  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:44  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:44  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:44  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:45  ->  Getting page: https://books.toscrape.com/catalogue/category/books/autobiography_27/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:45  ->  Request: GET https://books.toscrape.com/catalogue/category/books/autobiography_27/index.html
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:45  ->  8 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:45  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:45  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:45  ->  Moving on!
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:45  ->  7 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:45  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:45  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:45  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:45  ->  Moving on!
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:17 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-810a"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:45  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/autobiography_27/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:45  ->  Response: GET https://books.toscrape.com/catalogue/category/books/autobiography_27/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:45  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:45  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:46  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:46  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:46  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:46  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:46  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:46  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:46  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:46  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:46  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:46  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:46  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:46  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:47  ->  9 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:47  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:47  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:47  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:47  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/parenting_28/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:47  ->  Request: GET https://books.toscrape.com/catalogue/category/books/parenting_28/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:47  ->  Getting page: https://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:47  ->  Request: GET https://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:47  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:19 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-53f4"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:47  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/parenting_28/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:47  ->  Response: GET https://books.toscrape.com/catalogue/category/books/parenting_28/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:47  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:47  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:47  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:47  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:47  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:47  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:47  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:47  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:47  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:47  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:47  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:47  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:47  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:47  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:47  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092D0DD970>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:47  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:48  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:48  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:48  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:48  ->  Moving on!
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:48  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C65AFD0>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:20 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-5381"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:48  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:48  ->  Response: GET https://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:48  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:48  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:48  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:48  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:48  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:48  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:48  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:48  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:48  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:48  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:48  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:48  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:48  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:48  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:48  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:48  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:48  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:48  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:48  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:49  ->  Getting page: https://books.toscrape.com/catalogue/category/books/humor_30/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:49  ->  Request: GET https://books.toscrape.com/catalogue/category/books/humor_30/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:21 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-8ad6"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:49  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/humor_30/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:49  ->  Response: GET https://books.toscrape.com/catalogue/category/books/humor_30/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:49  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:49  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:49  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:49  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:49  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:49  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:49  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:49  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:49  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:49  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:49  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:49  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:49  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:49  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/horror_31/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:50  ->  Request: GET https://books.toscrape.com/catalogue/category/books/horror_31/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:22 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-adde"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:50  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/horror_31/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:50  ->  Response: GET https://books.toscrape.com/catalogue/category/books/horror_31/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:50  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:50  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:50  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:50  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:50  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:50  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:50  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:50  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:50  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:50  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:50  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:50  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:50  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:50  ->  Getting page: https://books.toscrape.com/catalogue/category/books/history_32/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:50  ->  Request: GET https://books.toscrape.com/catalogue/category/books/history_32/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:50  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:51  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:22 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-c096"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:51  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/history_32/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:51  ->  Response: GET https://books.toscrape.com/catalogue/category/books/history_32/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:51  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:51  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:51  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:51  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:51  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:51  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:51  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:51  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:51  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:51  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:51  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:51  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:51  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:51  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:51  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:51  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:51  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:53  ->  10 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:53  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:53  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:53  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:53  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:55  ->  Getting page: https://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:55  ->  Request: GET https://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:55  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:54:55  ->  close.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:55  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:55  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:55  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:55  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:55  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:55  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:27 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-d36c"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:55  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:55  ->  Response: GET https://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:55  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:56  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:56  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:56  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:56  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:56  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:56  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:56  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:56  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:56  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:56  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:56  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:56  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:56  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:56  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:56  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:56  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:56  ->  17 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:56  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:56  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:56  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:56  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:56  ->  18 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:56  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:56  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:56  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:56  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:58  ->  Getting page: https://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:58  ->  Request: GET https://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:30 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-705f"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:58  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:58  ->  Response: GET https://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:58  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:58  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:58  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:58  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:58  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:58  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:58  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:58  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:58  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:58  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:58  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:58  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:58  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:54:58  ->  Getting page: https://books.toscrape.com/catalogue/category/books/business_35/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:54:58  ->  Request: GET https://books.toscrape.com/catalogue/category/books/business_35/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:30 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-985e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:54:58  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/business_35/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:54:58  ->  Response: GET https://books.toscrape.com/catalogue/category/books/business_35/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:58  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:59  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:59  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:54:59  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:54:59  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:54:59  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:59  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:59  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:59  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:59  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:59  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:59  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:59  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:59  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:54:59  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:54:59  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:54:59  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:54:59  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:54:59  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:54:59  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:54:59  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:54:59  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:00  ->  20 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:00  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:00  ->  getting next page tag
[INFO|beautifulCrawler|WEB_SCRAPER|L332] - 2024-06-03 21:55:00  ->  going to next page
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:01  ->  12 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:01  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:01  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:01  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:01  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:01  ->  Getting page: https://books.toscrape.com/catalogue/category/books/biography_36/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:01  ->  Request: GET https://books.toscrape.com/catalogue/category/books/biography_36/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:01  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:01  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:01  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:01  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:01  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:33 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-6d54"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:02  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/biography_36/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:02  ->  Response: GET https://books.toscrape.com/catalogue/category/books/biography_36/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:02  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:02  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:02  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:02  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:02  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:02  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:02  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:02  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:02  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:02  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:02  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:02  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:02  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:02  ->  Getting page: https://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-2.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:02  ->  Request: GET https://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-2.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:34 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-8e9e"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:02  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-2.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:02  ->  Response: GET https://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-2.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:02  ->  receive_response_body.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:03  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:03  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:03  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:03  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:03  ->  Moving on!
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:03  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:03  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:03  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:03  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:03  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:03  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:03  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:03  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:03  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:03  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:03  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:03  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:03  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:03  ->  Getting page: https://books.toscrape.com/catalogue/category/books/thriller_37/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:03  ->  Request: GET https://books.toscrape.com/catalogue/category/books/thriller_37/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:03  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:04  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:35 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-8ce3"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:04  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/thriller_37/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:04  ->  Response: GET https://books.toscrape.com/catalogue/category/books/thriller_37/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:04  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:04  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:04  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:04  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:04  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:04  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:04  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:04  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:04  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:04  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:04  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:04  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:04  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:04  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:04  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:04  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:04  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:05  ->  Getting page: https://books.toscrape.com/catalogue/category/books/contemporary_38/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:05  ->  Request: GET https://books.toscrape.com/catalogue/category/books/contemporary_38/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:37 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-5f19"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:05  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/contemporary_38/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:05  ->  Response: GET https://books.toscrape.com/catalogue/category/books/contemporary_38/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:05  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:05  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:05  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:05  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:05  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:05  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:05  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:05  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:05  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:05  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:05  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:05  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:05  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:05  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:05  ->  10 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:05  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:05  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:05  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:05  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:06  ->  3 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:06  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:06  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:06  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:06  ->  11 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:06  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:06  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:06  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:06  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:07  ->  Getting page: https://books.toscrape.com/catalogue/category/books/spirituality_39/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:07  ->  Request: GET https://books.toscrape.com/catalogue/category/books/spirituality_39/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:39 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-73d1"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:07  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/spirituality_39/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:07  ->  Response: GET https://books.toscrape.com/catalogue/category/books/spirituality_39/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:07  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:07  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:07  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:07  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:07  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:07  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:07  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:07  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:07  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:07  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:07  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:07  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:07  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:07  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/academic_40/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:08  ->  Request: GET https://books.toscrape.com/catalogue/category/books/academic_40/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:08  ->  Getting page: https://books.toscrape.com/catalogue/category/books/self-help_41/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:08  ->  Request: GET https://books.toscrape.com/catalogue/category/books/self-help_41/index.html
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:08  ->  connect_tcp.started host='books.toscrape.com' port=443 local_address=None timeout=5.0 socket_options=None
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:39 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-536f"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:08  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/academic_40/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:08  ->  Response: GET https://books.toscrape.com/catalogue/category/books/academic_40/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:08  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:08  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:08  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:08  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:08  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:08  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:08  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:08  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:08  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:08  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:08  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:08  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:08  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:08  ->  connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092D0DD2E0>
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:08  ->  start_tls.started ssl_context=<ssl.SSLContext object at 0x000002092BD32940> server_hostname='books.toscrape.com' timeout=5.0
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:08  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:08  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:08  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:08  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:08  ->  Moving on!
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:08  ->  start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002092C869C70>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:08  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:09  ->  6 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:09  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:09  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:09  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:09  ->  Moving on!
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:09  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:40 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-6d5d"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:09  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/self-help_41/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:09  ->  Response: GET https://books.toscrape.com/catalogue/category/books/self-help_41/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:09  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:09  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:09  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:09  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:09  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:09  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:09  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:09  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:09  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:09  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:09  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:09  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:09  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:09  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:09  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:09  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:09  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:10  ->  5 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:10  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:10  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:10  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:10  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:10  ->  Getting page: https://books.toscrape.com/catalogue/category/books/historical_42/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:10  ->  Request: GET https://books.toscrape.com/catalogue/category/books/historical_42/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:10  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:10  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:10  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:10  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:10  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:11  ->  Getting page: https://books.toscrape.com/catalogue/category/books/christian_43/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:11  ->  Request: GET https://books.toscrape.com/catalogue/category/books/christian_43/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:42 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-598c"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:11  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/historical_42/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:11  ->  Response: GET https://books.toscrape.com/catalogue/category/books/historical_42/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:11  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:11  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:11  ->  saving data to db storage: BookScrape
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:42 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-6056"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:11  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/christian_43/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:11  ->  Response: GET https://books.toscrape.com/catalogue/category/books/christian_43/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:11  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:11  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:11  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:11  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:11  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:11  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:11  ->  2 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:11  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:11  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:11  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:11  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:12  ->  3 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:12  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:12  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:12  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:12  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:12  ->  Getting page: https://books.toscrape.com/catalogue/category/books/suspense_44/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:12  ->  Request: GET https://books.toscrape.com/catalogue/category/books/suspense_44/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:44 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-5372"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:12  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/suspense_44/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:12  ->  Response: GET https://books.toscrape.com/catalogue/category/books/suspense_44/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:12  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:12  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:12  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:12  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:12  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:12  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:12  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:12  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:12  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:12  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:12  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:12  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:12  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:12  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:13  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:13  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:13  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:13  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:13  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:13  ->  Getting page: https://books.toscrape.com/catalogue/category/books/short-stories_45/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:13  ->  Request: GET https://books.toscrape.com/catalogue/category/books/short-stories_45/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:13  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:13  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:13  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:13  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:13  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:13  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:45 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-5310"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:14  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/short-stories_45/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:14  ->  Response: GET https://books.toscrape.com/catalogue/category/books/short-stories_45/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:14  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:14  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:14  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:14  ->  Getting page: https://books.toscrape.com/catalogue/category/books/novels_46/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:14  ->  Request: GET https://books.toscrape.com/catalogue/category/books/novels_46/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  receive_response_headers.started request=<Request [b'GET']>
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:14  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:14  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:14  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:14  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:14  ->  Moving on!
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:46 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-53d0"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:14  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/novels_46/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:14  ->  Response: GET https://books.toscrape.com/catalogue/category/books/novels_46/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:14  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:14  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:14  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:14  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:14  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:14  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:14  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:14  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:14  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:14  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:14  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:15  ->  Getting page: https://books.toscrape.com/catalogue/category/books/health_47/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:15  ->  Request: GET https://books.toscrape.com/catalogue/category/books/health_47/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:46 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-6680"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:15  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/health_47/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:15  ->  Response: GET https://books.toscrape.com/catalogue/category/books/health_47/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:15  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:15  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:15  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:15  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:15  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:15  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:15  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:15  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:15  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:15  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:15  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:15  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:15  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:15  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:16  ->  4 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:16  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:16  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:16  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:16  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:16  ->  Getting page: https://books.toscrape.com/catalogue/category/books/politics_48/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:16  ->  Request: GET https://books.toscrape.com/catalogue/category/books/politics_48/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:48 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-608d"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:16  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/politics_48/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:16  ->  Response: GET https://books.toscrape.com/catalogue/category/books/politics_48/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  response_closed.complete
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:16  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:16  ->  close.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:16  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:16  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:16  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:16  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:16  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:16  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:16  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:16  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:16  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:16  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:16  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:16  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:16  ->  saving data to db storage: BookScrape
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:16  ->  Getting page: https://books.toscrape.com/catalogue/category/books/cultural_49/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:16  ->  Request: GET https://books.toscrape.com/catalogue/category/books/cultural_49/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:48 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-5315"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:16  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/cultural_49/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:16  ->  Response: GET https://books.toscrape.com/catalogue/category/books/cultural_49/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:16  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:16  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:16  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:16  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:17  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:17  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:17  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:17  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:17  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:17  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:17  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:17  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:17  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:17  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:17  ->  3 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:17  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:17  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:17  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:17  ->  Moving on!
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:17  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:17  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:17  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:17  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:17  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L479] - 2024-06-03 21:55:17  ->  Worker-3 completed task in time:  162.95s
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:18  ->  Getting page: https://books.toscrape.com/catalogue/category/books/erotica_50/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:18  ->  Request: GET https://books.toscrape.com/catalogue/category/books/erotica_50/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:49 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-5300"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:18  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/erotica_50/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:18  ->  Response: GET https://books.toscrape.com/catalogue/category/books/erotica_50/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:18  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:18  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:18  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:18  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:18  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:18  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:18  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:18  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:18  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:18  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:18  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:18  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:18  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:18  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:18  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:18  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:18  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:18  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:18  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L479] - 2024-06-03 21:55:18  ->  Worker-1 completed task in time:  164.46s
[INFO|beautifulCrawler|WEB_SCRAPER|L82] - 2024-06-03 21:55:19  ->  Getting page: https://books.toscrape.com/catalogue/category/books/crime_51/index.html
[DEBUG|beautifulCrawler|WEB_SCRAPER|L67] - 2024-06-03 21:55:19  ->  Request: GET https://books.toscrape.com/catalogue/category/books/crime_51/index.html
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  send_request_headers.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  send_request_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Jun 2024 20:55:51 GMT'), (b'Content-Type', b'text/html'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Last-Modified', b'Wed, 08 Feb 2023 21:02:32 GMT'), (b'ETag', b'W/"63e40de8-53f5"'), (b'Strict-Transport-Security', b'max-age=0; includeSubDomains; preload'), (b'Content-Encoding', b'br')])
[INFO|_client|httpx|L1773] - 2024-06-03 21:55:19  ->  HTTP Request: GET https://books.toscrape.com/catalogue/category/books/crime_51/index.html "HTTP/1.1 200 OK"
[INFO|beautifulCrawler|WEB_SCRAPER|L72] - 2024-06-03 21:55:19  ->  Response: GET https://books.toscrape.com/catalogue/category/books/crime_51/index.html - Status 200
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  receive_response_body.complete
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  response_closed.started
[DEBUG|_trace|httpcore.http11|L85] - 2024-06-03 21:55:19  ->  response_closed.complete
[INFO|beautifulCrawler|WEB_SCRAPER|L261] - 2024-06-03 21:55:19  ->  Parsing data
[INFO|beautifulCrawler|WEB_SCRAPER|L374] - 2024-06-03 21:55:19  ->  beginning pipeline
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:19  ->  Executing remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:19  ->  Finished execution of remove_nulls on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:19  ->  Executing clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:19  ->  Finished execution of clean_title on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:19  ->  Executing clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:19  ->  Finished execution of clean_rating on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:19  ->  Executing clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:19  ->  Finished execution of clean_price on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L390] - 2024-06-03 21:55:19  ->  Executing clean_link on dataset
[DEBUG|beautifulCrawler|WEB_SCRAPER|L392] - 2024-06-03 21:55:19  ->  Finished execution of clean_link on dataset
[INFO|beautifulCrawler|WEB_SCRAPER|L396] - 2024-06-03 21:55:19  ->  saving data to db storage: BookScrape
[INFO|storage|WEB_SCRAPER|L206] - 2024-06-03 21:55:20  ->  1 records inserted into database!
[INFO|beautifulCrawler|WEB_SCRAPER|L403] - 2024-06-03 21:55:20  ->  Pipeline process complete
[DEBUG|beautifulCrawler|WEB_SCRAPER|L321] - 2024-06-03 21:55:20  ->  getting next page tag
[DEBUG|beautifulCrawler|WEB_SCRAPER|L244] - 2024-06-03 21:55:20  ->  Tag was not find
[DEBUG|beautifulCrawler|WEB_SCRAPER|L245] - 2024-06-03 21:55:20  ->  Moving on!
[INFO|beautifulCrawler|WEB_SCRAPER|L479] - 2024-06-03 21:55:20  ->  Worker-2 completed task in time:  165.94s
[INFO|beautifulCrawler|WEB_SCRAPER|L444] - 2024-06-03 21:55:20  ->  Process completed in time:  165.95s
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:20  ->  close.started
[DEBUG|_trace|httpcore.connection|L85] - 2024-06-03 21:55:20  ->  close.complete
